{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "oldHeight": 276,
      "position": {
        "height": "298px",
        "left": "1149px",
        "right": "20px",
        "top": "454px",
        "width": "350px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "varInspector_section_display": "block",
      "window_display": true
    },
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yangxiaoming5201/hello-world/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwpxVKAt30w_"
      },
      "source": [
        "# **挂载硬盘**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qG0Rmdd6Yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e61806a-db41-438f-e385-0e71ec30a38f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4bbhAp2n6H1"
      },
      "source": [
        "# 引入外部库\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsxUXg2YnifU"
      },
      "source": [
        "#  !pip install  Queue "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPJSNwCmCpaG"
      },
      "source": [
        "# **库函数**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dvdorMlG8Yc"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib as mpl\r\n",
        "import os,datetime\r\n",
        "import seaborn as sns\r\n",
        "import tensorflow as tf\r\n",
        "from queue import Queue\r\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.layers import LSTM,Dropout,Dense,Activation\r\n",
        "from IPython.display import HTML\r\n",
        "from tensorflow.keras.regularizers import L2\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from google.colab import widgets\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWbaNOKKC9td",
        "outputId": "43a856c3-7d64-4cf4-bb90-3af0f8adfaa6"
      },
      "source": [
        "#指定默认字体\r\n",
        "mpl.rcParams['font.sans-serif'] = ['SimHei']\r\n",
        "mpl.rcParams['font.family']='sans-serif'\r\n",
        "#解决负号'-'显示为方块的问题\r\n",
        "mpl.rcParams['axes.unicode_minus'] = False\r\n",
        "print('Tensorflow is version:',tf.__version__)\r\n",
        "pd.set_option('display.max_rows',30)\r\n",
        "pd.set_option('display.max_columns',10)\r\n",
        "pd.set_option('colheader_justify', 'center')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow is version: 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu7nzbGP3We5"
      },
      "source": [
        "# **调用GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WoQeHSlRE90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9521bfe7-5bda-4c72-868e-9ed2df0eeaaf"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\r\n",
        "# if device_name != '/device:GPU:0':\r\n",
        "#   raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyVKHrjOBX_l"
      },
      "source": [
        "# **参数**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeKH8xG1buSg"
      },
      "source": [
        "#自可变参数\n",
        "#@title 全局变量参数 { form-width: \"350px\", display-mode: \"both\" }\n",
        "#数据存放路径\n",
        "root_path = \"/content/drive/MyDrive/Colab Notebooks/AirQ\" #@param {type:\"string\"}\n",
        "site_list=['100'+str(i+1)+'A' for i in range(12)]\n",
        "train_date = \"2019-12-31\" #@param {type:\"date\"}\n",
        "test_date = \"2020-03-31\" #@param {type:\"date\"}\n",
        "valid_date = \"2020-06-30\" #@param {type:\"date\"}\n",
        "train_site =  48960#@param {type:\"number\"}\n",
        "test_site = 51144 #@param {type:\"number\"}\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjC2el4jPxuZ"
      },
      "source": [
        "#不可手动修改参数\r\n",
        "file_list=[]#各个站点数据集的路径列表：12个站点\r\n",
        "data_list=[]#所有的数据列表;形状：（站点数，时间长度（53328）,输入变量）\r\n",
        "std_parmas_list = []  #标准化的相关参数,方便反标准化(均值/标准差)\r\n",
        "std_data_list = []  #标准化后的数据列表\r\n",
        "train_data_list=[]  #标准化后划分的训练集\r\n",
        "test_data_list=[]   #标准化后划分的测试集\r\n",
        "valid_data_list=[]  #标准化后划分的验证集\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDISDYsjBcXB"
      },
      "source": [
        "#@title 模型参数 { form-width: \"500px\", display-mode: \"both\" }\n",
        "timesteps=24 #@param {type:\"number\"}\n",
        "predict_steps=3 #@param {type:\"number\"}\n",
        "epochs =  60#@param {type:\"number\"}\n",
        "batchs =32#@param {type:\"number\"}\n",
        "init_learn_rate = 0.005 #@param {type:\"number\"}\n",
        "droupout_p = 0.5 #@param {type:\"number\"}\n",
        "L2_rate =  0.001#@param {type:\"number\"}\n",
        "lstm_hide_deep=1\n",
        "lstm_hide_nums=64\n",
        "\n",
        "#学习率相关设置\n",
        "rampup_epochs = 6\n",
        "sustain_epochs = 0\n",
        "start_lr = 0.001\n",
        "min_lr = 0.000001\n",
        "max_lr = 0.005\n",
        "exp_decay = 0.85"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkh5MEY4CmsV"
      },
      "source": [
        "# **数据处理**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-22T15:50:13.516348Z",
          "start_time": "2021-02-22T15:50:13.492383Z"
        },
        "id": "Y91h9gUnbWOq"
      },
      "source": [
        "\n",
        "def look_list_shape(look_list):\n",
        "    \"\"\"\n",
        "    查看list的维度\n",
        "    \"\"\"\n",
        "    print(np.array(look_list).shape)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-22T14:40:51.242360Z",
          "start_time": "2021-02-22T14:40:51.225406Z"
        },
        "id": "uDzsdyX2bWOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a82dd64-2295-4b7b-c78f-f35474768b24"
      },
      "source": [
        "file_list = [os.path.join(root_path, file) for file in os.listdir(root_path)]\n",
        "file_list.sort()\n",
        "file_list"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/AirQ/1001A_AirQ.xls',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AirQ/1002A_AirQ.xls',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AirQ/1003A_AirQ.xls',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AirQ/1004A_AirQ.xls',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AirQ/1005A_AirQ.xls',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AirQ/1006A_AirQ.xls',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AirQ/1007A_AirQ.xls',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AirQ/1008A_AirQ.xls',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AirQ/1009A_AirQ.xls',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AirQ/1010A_AirQ.xls',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AirQ/1011A_AirQ.xls',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AirQ/1012A_AirQ.xls']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC8GyE1jF4WJ"
      },
      "source": [
        "# **读取所有数据**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-22T14:41:23.337317Z",
          "start_time": "2021-02-22T14:40:51.245353Z"
        },
        "id": "TIFJu-_DbWOo"
      },
      "source": [
        "# \n",
        "def read_data():\n",
        "  data_list.clear()#\n",
        "  for file in file_list:\n",
        "      data =pd.read_excel(file,usecols=[0, 2, 3, 4, 6, 8, 10, 12, 16])\n",
        "      data.date=data.date.astype(\"str\")\n",
        "      data.date=pd.to_datetime(data.date,format='%Y-%m-%d')\n",
        "      # 将CO放大1000背\n",
        "      data.CO=data.CO*1000\n",
        "      data_list.append(data)\n",
        "read_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ59w-5LeHzH"
      },
      "source": [
        "# **查看数据**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-wBDGeMeHUJ"
      },
      "source": [
        "def look_data(datalist):\r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  for data in datalist:\r\n",
        "    with tb.output_to(i, select=(i == 0)):\r\n",
        "      print(data.head(24))\r\n",
        "      i+=1\r\n",
        "look_data(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQm9MMYHJqVz"
      },
      "source": [
        "#**相关性热力分析**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeakO1zVJNg7"
      },
      "source": [
        "def data_heatmap(datalist):\r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  for data in datalist:\r\n",
        "    new_data=data.set_index(['date','hour'])\r\n",
        "    with tb.output_to(i, select=(i == 0)):\r\n",
        "      corr=new_data.corr()\r\n",
        "      plt.figure( figsize=(10,6))\r\n",
        "      sns.heatmap(corr,annot=True)\r\n",
        "      plt.show()\r\n",
        "      i+=1\r\n",
        "data_heatmap(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jeNSTaTJ1sH"
      },
      "source": [
        "# **删除O3数据**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_YkmqtGJ0d_"
      },
      "source": [
        "for data in data_list:\r\n",
        "  try:\r\n",
        "    data.drop(['O3'],inplace=True,axis=1)\r\n",
        "  except:\r\n",
        "    pass\r\n",
        "print(\"O3数据已经剔除\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1mkDM8ECR8Y"
      },
      "source": [
        "# **查看数据的描述信息**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmv-d57PCRpb"
      },
      "source": [
        "def look_data_desc(datalist): \r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  for data in datalist:\r\n",
        "    new_data=data.set_index(['date','hour'])\r\n",
        "    with tb.output_to(i, select=(i == 0)):\r\n",
        "      print(new_data.describe())\r\n",
        "      i+=1\r\n",
        "look_data_desc(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNnXX99r5CK0"
      },
      "source": [
        "# **原始数据可视化**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIYhW7UJE7Pi"
      },
      "source": [
        "def data_plot(datalist): \r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  for data in datalist:\r\n",
        "    new_data=data.set_index(['date','hour'])\r\n",
        "    with tb.output_to(i, select=(i == 0)):\r\n",
        "      new_data.plot(subplots=True,figsize=(25,15))\r\n",
        "      plt.show()\r\n",
        "      i+=1\r\n",
        "data_plot(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWEXqvPT8kpC"
      },
      "source": [
        "# **查看缺失值**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUBDj2mKVQvR"
      },
      "source": [
        "def look_nan(datalist):\r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  for data in datalist:\r\n",
        "    new_data=data.set_index(['date','hour'])\r\n",
        "    with tb.output_to(i, select=(i == 0)):\r\n",
        "      print(new_data.isnull().sum())\r\n",
        "      i+=1\r\n",
        "look_nan(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Ab0UQL-qHB"
      },
      "source": [
        "# **查看0值**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RDcIO7s-pca"
      },
      "source": [
        "def look_zero(datalist):\r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  for data in datalist:\r\n",
        "    new_data=data.set_index(['date','hour'])\r\n",
        "    with tb.output_to(i, select=(i == 0)):\r\n",
        "      print(new_data)\r\n",
        "      print((new_data==0).astype(int).any())\r\n",
        "      i+=1\r\n",
        "look_zero(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK_UW6dw_o-z"
      },
      "source": [
        "# **处理0值**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtuFjtua_njA"
      },
      "source": [
        "def ffill_zero(datalist):\r\n",
        "  for data in datalist:\r\n",
        "    data.replace(0,np.nan,inplace=True)\r\n",
        "    data['hour'].fillna(0,inplace=True)\r\n",
        "    data.fillna(method=\"ffill\",inplace=True)\r\n",
        "ffill_zero(data_list)\r\n",
        "look_zero(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtiwMo2NFHG4"
      },
      "source": [
        "# **箱型图查看数据平稳性**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaXS_CHTFFuu"
      },
      "source": [
        "def data_boxplot(datalist):\r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  for data in datalist:\r\n",
        "    new_data=data.set_index(['date','hour'])\r\n",
        "    with tb.output_to(i, select=(i == 0)):\r\n",
        "      plt.figure(figsize=(10,10))\r\n",
        "      new_data.CO/=100\r\n",
        "      new_data.boxplot()\r\n",
        "      plt.show()\r\n",
        "      i+=1\r\n",
        "data_boxplot(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnQd2CMXHFL4"
      },
      "source": [
        "# **处理离群点**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrh-VZU_06tz"
      },
      "source": [
        "class ThreeQueue(list):\r\n",
        "    def __init__(self,len):\r\n",
        "        super().__init__()\r\n",
        "        self.len=len\r\n",
        "\r\n",
        "    def add(self, num):\r\n",
        "        if len(self) == self.len:\r\n",
        "            self.pop(0)\r\n",
        "        self.append(num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-I1KliXHE85"
      },
      "source": [
        "outer_distance=3#选取多大步长处理离群点\r\n",
        "def data_quantile(datalist):\r\n",
        "  data_list_outer=[]\r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  for data in datalist:\r\n",
        "    new_data=data.set_index(['date','hour'])\r\n",
        "    with tb.output_to(i, select=(i == 0)):\r\n",
        "      quantile=new_data.quantile([0.25,0.5,0.75], numeric_only=True)\r\n",
        "      one_four=quantile[quantile.index==0.25].reset_index(drop=True)\r\n",
        "      one_two=quantile[quantile.index==0.5].reset_index(drop=True)\r\n",
        "      third_four=quantile[quantile.index==0.75].reset_index(drop=True)\r\n",
        "      outer=one_two+(third_four-one_four)*1.5\r\n",
        "      print('各个特征值离群点判定值：\\n\\n',outer)\r\n",
        "      new_data=new_data[new_data<=outer.iloc[0,:]]\r\n",
        "      print('各组特征值离群点数如下：\\n',pd.isna(new_data).astype(int).sum())\r\n",
        "\r\n",
        "      rows=len(new_data)\r\n",
        "      cols=len(new_data.columns)\r\n",
        "\r\n",
        "      for col in range(cols):\r\n",
        "        #调试----------\r\n",
        "        # col=2\r\n",
        "        # ----------------\r\n",
        "\r\n",
        "        tq_front=ThreeQueue(outer_distance)\r\n",
        "        tq_after=ThreeQueue(outer_distance)\r\n",
        "        j=0#确定后面下一个数位置\r\n",
        "\r\n",
        "        \r\n",
        "        for row in range(rows):\r\n",
        "          #调试----------\r\n",
        "          # if row==1000:\r\n",
        "          #     return\r\n",
        "          # ----------------\r\n",
        "\r\n",
        "          loc_num=new_data.iloc[row,col]\r\n",
        "          if row==0:\r\n",
        "            while len(tq_after)<outer_distance:\r\n",
        "              num=new_data.iloc[j,col]\r\n",
        "              if not pd.isna(num):\r\n",
        "                tq_after.add(num)\r\n",
        "              j+=1\r\n",
        "\r\n",
        "          if pd.isna(loc_num):\r\n",
        "            new_data.iloc[row,col]=np.mean(tq_front+tq_after)\r\n",
        "\r\n",
        "            # -------调试---------\r\n",
        "            # print(tq_front,tq_after)\r\n",
        "            # print(j)\r\n",
        "            # print( new_data.iloc[row,col])\r\n",
        "            # ----------------\r\n",
        "            \r\n",
        "          else:\r\n",
        "             while j < rows:\r\n",
        "               num=new_data.iloc[j,col]\r\n",
        "               if not pd.isna(num):\r\n",
        "                 tq_after.add(num)\r\n",
        "                 j+=1\r\n",
        "                 break\r\n",
        "               j+=1\r\n",
        "          tq_front.add(new_data.iloc[row,col])\r\n",
        "      new_date=new_data.reset_index()\r\n",
        "      data_list_outer.append(new_date)\r\n",
        "      filename=f'/content/drive/MyDrive/Colab Notebooks/Outer Data/{site_list[i]}_AirQ.csv'\r\n",
        "      print(filename+' 已被保存')\r\n",
        "      new_date.to_csv(filename,index=False)\r\n",
        "      i+=1\r\n",
        "  return data_list_outer\r\n",
        "data_list[0]\r\n",
        "data_list_outer=data_quantile(data_list)#返回处理过离群点后的数据"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwAV57-psIGw"
      },
      "source": [
        " 相关检验"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfXSvcFz1vKl"
      },
      "source": [
        "data_boxplot(data_list_outer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpyngRaLo0PM"
      },
      "source": [
        "# **对数化处理**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYdP1kfYo-Ea"
      },
      "source": [
        "def data_log10(datalist):\r\n",
        "  data_log10_list=[]\r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  for data in datalist:\r\n",
        "    new_data=data.set_index(['date','hour'])\r\n",
        "    with tb.output_to(i, select=(i == 0)):\r\n",
        "      new_data = new_data.replace('[0-1]', 1, regex=True)\r\n",
        "      new_data_log10=np.log10(new_data).reset_index()\r\n",
        "      data_log10_list.append(new_data_log10)\r\n",
        "      print(new_data_log10)\r\n",
        "      i+=1\r\n",
        "  return data_log10_list\r\n",
        "data_log10_list=data_log10(data_list_outer)#返回经过对数化处理的列表数据"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU4PqqByRDks"
      },
      "source": [
        "# **反对数化**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxJYQBcsRCY_"
      },
      "source": [
        "def anti_log10_data(datalist):\r\n",
        "  anti_log10_list=[]\r\n",
        "  for data in datalist:\r\n",
        "    new_data=np.power(10,data)\r\n",
        "    anti_log10_list.append(new_data)\r\n",
        "  return anti_log10_list\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVMnO9kOsWG7"
      },
      "source": [
        "相关检验"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9Etxdj4sFHf"
      },
      "source": [
        "data_heatmap(data_log10_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUz1ajumC4h6"
      },
      "source": [
        "# **数据缩放(归一化：0，标准化：1)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6xT7Yd6VEHe"
      },
      "source": [
        "zoom_method=1\r\n",
        "def data_zoom(datalist,method=0):\r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  zoom_class_list=[]\r\n",
        "  zoom_data_list=[]\r\n",
        "  for data in datalist:\r\n",
        "    with tb.output_to(i, select=(i == 0)):\r\n",
        "      new_data=data.set_index(['date','hour'])\r\n",
        "      print(new_data)\r\n",
        "      if method==0:\r\n",
        "        style=MinMaxScaler()\r\n",
        "      else:\r\n",
        "        style=StandardScaler()\r\n",
        "      style.fit(new_data)\r\n",
        "      zoom_class_list.append(style)\r\n",
        "      nl_data=style.transform(new_data)\r\n",
        "      print(nl_data)\r\n",
        "      zoom_data_list.append(nl_data)\r\n",
        "      i+=1\r\n",
        "  return zoom_data_list,zoom_class_list\r\n",
        "zoom_data_list,zoom_class_list=data_zoom(data_log10_list,zoom_method)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9KaL7ylG3oB"
      },
      "source": [
        "# **反数据缩放**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td7QqnDDG21y"
      },
      "source": [
        "def data_anti_zoom(datalist,class_list):\r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  anti_zoom_data=[]\r\n",
        "  for data,style in zip(datalist,class_list):\r\n",
        "    with tb.output_to(i, select=(i == 0)):\r\n",
        "      anti_data=style.inverse_transform(data)\r\n",
        "      anti_zoom_data.append(anti_data)\r\n",
        "      # print(anti_data)\r\n",
        "      i+=1\r\n",
        "  return anti_zoom_data\r\n",
        "anti_zoom_data=data_anti_zoom(zoom_data_list,zoom_class_list)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-22T14:41:23.409143Z",
          "start_time": "2021-02-22T14:41:23.339300Z"
        },
        "id": "M0CHiQoAbWOo"
      },
      "source": [
        "data1=data_list[1]\r\n",
        "print(data1[data1.date==train_date],'\\n---------------------------\\n')\r\n",
        "print(data1[data1.date==test_date],'\\n---------------------------\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWErQq0coIzR"
      },
      "source": [
        "# **划分数据集**(训练集、验证集、测试集)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-22T16:44:05.420362Z",
          "start_time": "2021-02-22T16:44:05.337585Z"
        },
        "id": "WUxdcs_KbWOq"
      },
      "source": [
        "def split_dataset(dataset_list):\n",
        "    \"\"\"\n",
        "    划分数据集\n",
        "    \"\"\"\n",
        "    train_data_list.clear()  #标准化后划分的训练集\n",
        "    test_data_list.clear()   #标准化后划分的测试集\n",
        "    valid_data_list.clear()  #标准化后划分的验证集 \n",
        "    \n",
        "    for dataset in dataset_list:\n",
        "        train_data=dataset[:train_site]\n",
        "        train_data_list.append(train_data)\n",
        "\n",
        "        test_data=dataset[train_site:test_site]\n",
        "        test_data_list.append(test_data)\n",
        "\n",
        "        valid_data=dataset[test_site:]\n",
        "        valid_data_list.append(valid_data)\n",
        "        # print(trainX.shape,testX.shape,validX.shape,'-----------\\n'\n",
        "split_dataset(zoom_data_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bZUAYVSecJv"
      },
      "source": [
        "look_list_shape(train_data_list)\r\n",
        "look_list_shape(test_data_list)\r\n",
        "look_list_shape(valid_data_list)\r\n",
        "(44544/24,6600/24,2184/24)\r\n",
        "test_data_list[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_0dr32coXgr"
      },
      "source": [
        "# **划分特征集与目标集**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-22T16:45:52.829601Z",
          "start_time": "2021-02-22T16:45:52.825580Z"
        },
        "id": "eoLaG2ldbWOq"
      },
      "source": [
        "def get_X_Y(data):\r\n",
        "  x_y_list=[]\r\n",
        "  for dataset in data:\r\n",
        "    x_y_tuple=()\r\n",
        "    datax=[]#构造x\r\n",
        "    datay=[]#构造y\r\n",
        "    for each in range(0,len(dataset)-timesteps - predict_steps,predict_steps):\r\n",
        "        x = dataset[each:each+timesteps]\r\n",
        "        y = dataset[each+timesteps:each+timesteps+predict_steps]\r\n",
        "        datax.append(x)\r\n",
        "        datay.append(y)\r\n",
        "    x_y_tuple=(np.array(datax),np.array(datay))\r\n",
        "    x_y_list.append(x_y_tuple)\r\n",
        "  return x_y_list\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS7MBivTk5d-"
      },
      "source": [
        "train_x_y_list=get_X_Y(train_data_list)\r\n",
        "\r\n",
        "test_x_y_list=get_X_Y(test_data_list)\r\n",
        "\r\n",
        "valid_x_y_list=get_X_Y(valid_data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOpYaTIthv9E"
      },
      "source": [
        "for train_x_y_tuple,valid_x_y_tuple,test_x_y_tuple in zip(train_x_y_list,valid_x_y_list,test_x_y_list):\r\n",
        "  train_x=train_x_y_tuple[0]\r\n",
        "  train_y=train_x_y_tuple[1]\r\n",
        "  valid_x=valid_x_y_tuple[0]\r\n",
        "  valid_y=valid_x_y_tuple[1]\r\n",
        "  test_x=test_x_y_tuple[0]\r\n",
        "  test_y=test_x_y_tuple[1]\r\n",
        "  print(train_x.shape,train_y.shape,test_y.shape)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ-hOjnnMsd_"
      },
      "source": [
        "input_dim=train_x_y_list[0][0].shape[2]\r\n",
        "input_dim#输入维度"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPK74_IrolJy"
      },
      "source": [
        "# **构建学习率下降函数**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyL-d9y2yfCb"
      },
      "source": [
        "# def scheduler(epoch):\n",
        "#     # 前5个epoch学习率保持不变，5个epoch后学习率按比例衰减\n",
        "#     if epoch < 5:\n",
        "#         return init_learn_rate\n",
        "#     else:\n",
        "#         lr = init_learn_rate * tf.math.exp(0.1 * (5 - epoch))\n",
        "#         return lr.numpy()\n",
        "\n",
        "def scheduler(epoch):\n",
        "  if epoch < rampup_epochs:\n",
        "    return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
        "  elif epoch < rampup_epochs + sustain_epochs:\n",
        "    return max_lr\n",
        "  else:\n",
        "    return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
        "    \n",
        "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda epoch: scheduler(epoch), verbose=True)\n",
        "rang = np.arange(epochs)\n",
        "y = [scheduler(x) for x in rang]\n",
        "plt.plot(rang, y)\n",
        "print('Learning rate per epoch:')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qpv8LDFouEQ"
      },
      "source": [
        "# **构建DM-LSTM模型**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwNO274vuhcK"
      },
      "source": [
        "# 使用3层LSTM，输出层为2输出的Dense层\r\n",
        "\r\n",
        "def create_model():\r\n",
        "  model = Sequential()\r\n",
        "  model.add(LSTM(64 ,activation='tanh',recurrent_activation='sigmoid',bias_initializer='zero',unit_forget_bias=True,input_shape=(timesteps,input_dim),use_bias=True,recurrent_regularizer=L2(L2_rate),return_sequences=True))\r\n",
        "  model.add(Dropout(droupout_p))\r\n",
        "  for i in range(lstm_hide_deep):\r\n",
        "    if i==lstm_hide_deep-1:\r\n",
        "      model.add(LSTM(lstm_hide_nums,activation='tanh',recurrent_activation='sigmoid',bias_initializer='zero',unit_forget_bias=True,recurrent_regularizer=L2(L2_rate),use_bias=True, return_sequences=False))\r\n",
        "      model.add(Dropout(droupout_p))\r\n",
        "      break\r\n",
        "    model.add(LSTM(lstm_hide_nums ,activation='tanh',recurrent_activation='sigmoid',bias_initializer='zero',unit_forget_bias=True,input_shape=(timesteps,input_dim),use_bias=True,recurrent_regularizer=L2(L2_rate),return_sequences=True))\r\n",
        "    model.add(Dropout(droupout_p))\r\n",
        "  # model.add(Activation('sigmoid'))1\r\n",
        "  model.add(Dense(predict_steps*input_dim))\r\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\r\n",
        "  return model\r\n",
        "\r\n",
        "model=create_model()\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qF8_fv-o1q4"
      },
      "source": [
        "# **打印模型结构图**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-tEBNFP2vDX"
      },
      "source": [
        "tf.keras.utils.plot_model(model,show_shapes = True,show_dtype=True,expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpU8U54ko6lR"
      },
      "source": [
        "# **训练模型**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAPqGMs-4x7J"
      },
      "source": [
        "def train_model():\r\n",
        "  # if os.path.exists(\"./drive/MyDrive/checkpoints/checkpoint\"):\r\n",
        "  #     print(\"《《《《《《《《《《《《《训练的模型权重已经被加载》》》》》》》》》》》\")\r\n",
        "  #      model.load_weights(f'./drive/MyDrive/checkpoints/MyModel_t+{predict_steps}')\r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  for train_x_y_tuple,valid_x_y_tuple in zip(train_x_y_list,valid_x_y_list):\r\n",
        "     with tb.output_to(i, select=(i == 0)):\r\n",
        "        train_x=train_x_y_tuple[0]\r\n",
        "        train_y=train_x_y_tuple[1]\r\n",
        "        valid_x=valid_x_y_tuple[0]\r\n",
        "        valid_y=valid_x_y_tuple[1]\r\n",
        "        # logdir=os.path.join(\"logs\",datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n",
        "        # tc=tf.keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1)\r\n",
        "        history =model.fit(train_x, train_y.reshape(train_y.shape[0],-1),\r\n",
        "                          epochs=epochs,\r\n",
        "                          batch_size=batchs,\r\n",
        "                          verbose=1,\r\n",
        "                          validation_data=(valid_x, valid_y.reshape(valid_y.shape[0],-1)),callbacks=[reduce_lr])\r\n",
        "        loss = history.history['loss']\r\n",
        "        val_loss = history.history['val_loss']\r\n",
        "        print(loss)\r\n",
        "        plt.plot(range(len(loss)), loss, 'b-', label='loss')\r\n",
        "        plt.plot(range(len(loss)), val_loss, 'r-', label='val_loss')\r\n",
        "        plt.legend(loc='best')\r\n",
        "        plt.show()\r\n",
        "        print(site_list[i]+'步Model已经保存')\r\n",
        "        model.save_weights(f'./drive/MyDrive/checkpoints/MyModel_t+{predict_steps}')\r\n",
        "        i+=1\r\n",
        "train_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvSO1KcLpBpx"
      },
      "source": [
        "# **获取预测的真实比例值**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn6g72TQyC1P"
      },
      "source": [
        "def get_predict_data(datalist):\r\n",
        "  global zoom_method,model\r\n",
        "  i=0\r\n",
        "  y_pre_zoom_list=[]\r\n",
        "  y_true_zoom_list=[]\r\n",
        "  #直接的预测数据\r\n",
        "  for data in datalist:\r\n",
        "      x_true=data[0]\r\n",
        "      y_true=data[1]\r\n",
        "      y_true=y_true.reshape(y_true.shape[0],-1)\r\n",
        "      y_true_zoom_list.append(y_true.reshape(-1,input_dim))\r\n",
        "\r\n",
        "      y_pre=model.predict(x_true)\r\n",
        "      y_pre=y_pre.reshape(-1,input_dim)\r\n",
        "      # print(y_pre.shape)\r\n",
        "      y_pre_zoom_list.append(y_pre)\r\n",
        "      # lo=np.sqrt(mean_squared_error(testy,pre_y))\r\n",
        "      \r\n",
        "  #反缩放的预测数据\r\n",
        "  \r\n",
        "  y_pre_log10_list=data_anti_zoom(y_pre_zoom_list,zoom_class_list)\r\n",
        "  y_true_log10__list=data_anti_zoom(y_true_zoom_list,zoom_class_list)\r\n",
        "\r\n",
        "  #反对数化数据\r\n",
        "  y_pre_list=anti_log10_data(y_pre_log10_list)\r\n",
        "  y_true_list=anti_log10_data(y_true_log10__list)\r\n",
        "  return y_pre_list,y_true_list\r\n",
        "y_pre_list,y_true_list=get_predict_data(test_x_y_list)\r\n",
        "print(y_true_list[0].shape,y_pre_list[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mNI1U8MXXyb"
      },
      "source": [
        "# **做出对比图**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYMtMjgzXU6N"
      },
      "source": [
        "def pre_true_plot(true_list,pre_list):\r\n",
        "  tb = widgets.TabBar(site_list)\r\n",
        "  i=0\r\n",
        "  for true_data,pre_data in zip(true_list,pre_list):\r\n",
        "     with tb.output_to(i, select=(i == 0)):\r\n",
        "       \r\n",
        "       print('mse:',mean_squared_error(true_data,pre_data))\r\n",
        "       print('rmse:',np.sqrt(mean_squared_error(true_data,pre_data)))\r\n",
        "       \r\n",
        "       plt.figure(figsize=(15,10))\r\n",
        "       plt.plot(true_data[:500,1],label='true data')\r\n",
        "       plt.plot(pre_data[:500,1],label='predict data')\r\n",
        "       plt.legend()\r\n",
        "       plt.show()\r\n",
        "       i+=1\r\n",
        "pre_true_plot(y_true_list,y_pre_list)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edYk7n1Zsfv0"
      },
      "source": [
        "model.load_weights(f'./drive/MyDrive/checkpoints/MyModel_t+{predict_steps}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN2XNwGxpIOu"
      },
      "source": [
        "# **生成真实值与预测值的折线图**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WufkF_XH27BF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}